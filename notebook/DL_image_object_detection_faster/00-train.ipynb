{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN训练部分\n",
    "在接下来的部分中，我们对Faster R-CNN进行训练。为了减少训练时间，我们在预训练模型的基础上进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelarts.session import Session\n",
    "sess = Session()\n",
    "sess.download_data(bucket_path=\"/modelarts-labs/notebook/DL_object_detection_faster/frcnn.tar\", path=\"./faster.tar\")\n",
    "!tar -xf ./faster.tar\n",
    "!rm -r ./faster.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安装与引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: pycocotools in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: torchvision==0.3 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: six in /home/ma-user/modelarts-sdk (from torchvision==0.3) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchvision==0.3) (5.0.0)\n",
      "Requirement already satisfied: torch>=1.1.0 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchvision==0.3) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchvision==0.3) (1.14.5)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Uninstalling protobuf-3.9.1:\n",
      "  Successfully uninstalled protobuf-3.9.1\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting protobuf\n",
      "\u001b[?25l  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 59.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /home/ma-user/modelarts-sdk (from protobuf) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from protobuf) (41.0.0)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.9.1\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools\n",
    "!pip install torchvision==0.3\n",
    "!pip uninstall -y protobuf\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools._init_paths\n",
    "\n",
    "import tensorboardX as tb\n",
    "from datasets.factory import get_imdb\n",
    "from model.train_val import get_training_roidb, train_net\n",
    "from model.config import cfg, cfg_from_file, cfg_from_list, get_output_dir, get_output_tb_dir\n",
    "\n",
    "import roi_data_layer.roidb as rdl_roidb\n",
    "from roi_data_layer.layer import RoIDataLayer\n",
    "import utils.timer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from nets.vgg16 import vgg16\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练中的参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_name = \"voc_2007_trainval\"\n",
    "imdbval_name = \"voc_2007_test\"\n",
    "# 使用的预训练模型位置\n",
    "weight = \"../data/imagenet_weights/vgg16.pth\"\n",
    "# 迭代次数\n",
    "max_iters = 1200\n",
    "# cfg模型文件位置\n",
    "cfg_file = None\n",
    "set_cfgs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义加载数据集函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_roidb(imdb_names):\n",
    "    \n",
    "    def get_roidb(imdb_name):\n",
    "        # 加载数据集\n",
    "        imdb = get_imdb(imdb_name)\n",
    "        print('Loaded dataset `{:s}` for training'.format(imdb.name))\n",
    "        # 使用ground truth作为数据集策略\n",
    "        imdb.set_proposal_method(cfg.TRAIN.PROPOSAL_METHOD)\n",
    "        print('Set proposal method: {:s}'.format(cfg.TRAIN.PROPOSAL_METHOD))\n",
    "        roidb = get_training_roidb(imdb)\n",
    "        return roidb\n",
    "\n",
    "    roidbs = [get_roidb(s) for s in imdb_names.split('+')]\n",
    "    roidb = roidbs[0]\n",
    "    if len(roidbs) > 1:\n",
    "        for r in roidbs[1:]:\n",
    "            roidb.extend(r)\n",
    "        tmp = get_imdb(imdb_names.split('+')[1])\n",
    "        imdb = datasets.imdb.imdb(imdb_names, tmp.classes)\n",
    "    else:\n",
    "        imdb = get_imdb(imdb_names)\n",
    "    return imdb, roidb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'TRAIN': {'LEARNING_RATE': 0.001, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'GAMMA': 0.1, 'STEPSIZE': [30000], 'DISPLAY': 10, 'DOUBLE_BIAS': True, 'TRUNCATED': False, 'BIAS_DECAY': False, 'USE_GT': False, 'ASPECT_GROUPING': False, 'SNAPSHOT_KEPT': 3, 'SUMMARY_INTERVAL': 180, 'SCALES': [600], 'MAX_SIZE': 1000, 'IMS_PER_BATCH': 1, 'BATCH_SIZE': 128, 'FG_FRACTION': 0.25, 'FG_THRESH': 0.5, 'BG_THRESH_HI': 0.5, 'BG_THRESH_LO': 0.1, 'USE_FLIPPED': True, 'BBOX_REG': True, 'BBOX_THRESH': 0.5, 'SNAPSHOT_ITERS': 5000, 'SNAPSHOT_PREFIX': 'res101_faster_rcnn', 'BBOX_NORMALIZE_TARGETS': True, 'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0], 'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True, 'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0], 'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2], 'PROPOSAL_METHOD': 'gt', 'HAS_RPN': True, 'RPN_POSITIVE_OVERLAP': 0.7, 'RPN_NEGATIVE_OVERLAP': 0.3, 'RPN_CLOBBER_POSITIVES': False, 'RPN_FG_FRACTION': 0.5, 'RPN_BATCHSIZE': 256, 'RPN_NMS_THRESH': 0.7, 'RPN_PRE_NMS_TOP_N': 12000, 'RPN_POST_NMS_TOP_N': 2000, 'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0], 'RPN_POSITIVE_WEIGHT': -1.0, 'USE_ALL_GT': True}, 'TEST': {'SCALES': [600], 'MAX_SIZE': 1000, 'NMS': 0.3, 'SVM': False, 'BBOX_REG': True, 'HAS_RPN': False, 'PROPOSAL_METHOD': 'gt', 'RPN_NMS_THRESH': 0.7, 'RPN_PRE_NMS_TOP_N': 6000, 'RPN_POST_NMS_TOP_N': 300, 'MODE': 'nms', 'RPN_TOP_N': 5000}, 'RESNET': {'MAX_POOL': False, 'FIXED_BLOCKS': 1}, 'MOBILENET': {'REGU_DEPTH': False, 'FIXED_LAYERS': 5, 'WEIGHT_DECAY': 4e-05, 'DEPTH_MULTIPLIER': 1.0}, 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]), 'RNG_SEED': 3, 'ROOT_DIR': '/home/ma-user/work', 'DATA_DIR': '/home/ma-user/work/data', 'MATLAB': 'matlab', 'EXP_DIR': 'default', 'USE_GPU_NMS': True, 'POOLING_MODE': 'align', 'POOLING_SIZE': 7, 'ANCHOR_SCALES': [8, 16, 32], 'ANCHOR_RATIOS': [0.5, 1, 2], 'RPN_CHANNELS': 512}\n",
      "Loaded dataset `voc_2007_trainval` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "voc_2007_trainval gt roidb loaded from /home/ma-user/work/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "done\n",
      "10022 roidb entries\n",
      "Output will be saved to `/home/ma-user/work/output/default/voc_2007_trainval/default`\n",
      "TensorFlow summaries will be saved to `/home/ma-user/work/tensorboard/default/voc_2007_trainval/default`\n",
      "Loaded dataset `voc_2007_test` for training\n",
      "Set proposal method: gt\n",
      "Preparing training data...\n",
      "voc_2007_test gt roidb loaded from /home/ma-user/work/data/cache/voc_2007_test_gt_roidb.pkl\n",
      "done\n",
      "4952 validation roidb entries\n"
     ]
    }
   ],
   "source": [
    "if cfg_file is not None:\n",
    "    cfg_from_file(cfg_file)\n",
    "if set_cfgs is not None:\n",
    "    cfg_from_list(set_cfgs)\n",
    "\n",
    "print('Using config:')\n",
    "print(cfg)\n",
    "\n",
    "np.random.seed(cfg.RNG_SEED)\n",
    "\n",
    "# 加载训练数据集\n",
    "imdb, roidb = combined_roidb(imdb_name)\n",
    "print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "# 设置输出路径\n",
    "output_dir = get_output_dir(imdb,None)\n",
    "print('Output will be saved to `{:s}`'.format(output_dir))\n",
    "\n",
    "# 设置日志保存路径\n",
    "tb_dir = get_output_tb_dir(imdb, None)\n",
    "print('TensorFlow summaries will be saved to `{:s}`'.format(tb_dir))\n",
    "\n",
    "# 加载验证数据集\n",
    "orgflip = cfg.TRAIN.USE_FLIPPED\n",
    "cfg.TRAIN.USE_FLIPPED = False\n",
    "_, valroidb = combined_roidb(imdbval_name)\n",
    "print('{:d} validation roidb entries'.format(len(valroidb)))\n",
    "cfg.TRAIN.USE_FLIPPED = orgflip\n",
    "\n",
    "# 创建backbone网络\n",
    "# 在案例中使用的是VGG16模型，可以尝试其他不同的模型结构，例如Resnet等\n",
    "net = vgg16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 0 roidb entries: 10022 -> 10022\n",
      "Filtered 0 roidb entries: 4952 -> 4952\n",
      "Solving...\n"
     ]
    }
   ],
   "source": [
    "from model.train_val import filter_roidb, SolverWrapper\n",
    "# 对ROI进行筛选，将无效的ROI数据筛选掉\n",
    "roidb = filter_roidb(roidb)\n",
    "valroidb = filter_roidb(valroidb)\n",
    "\n",
    "sw = SolverWrapper(\n",
    "    net,\n",
    "    imdb,\n",
    "    roidb,\n",
    "    valroidb,\n",
    "    output_dir,\n",
    "    tb_dir,\n",
    "    pretrained_model=weight)\n",
    "\n",
    "print('Solving...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['net', 'imdb', 'roidb', 'valroidb', 'output_dir', 'tbdir', 'tbvaldir', 'pretrained_model'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 显示所有模型属性\n",
    "sw.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16()\n"
     ]
    }
   ],
   "source": [
    "# 此时的sw.net为backbone\n",
    "print(sw.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model snapshots from /home/ma-user/work/output/default/voc_2007_trainval/default/res101_faster_rcnn_iter_1000.pth\n",
      "Restored.\n",
      "网络结构\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vgg16(\n",
       "  (vgg): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Dropout(p=0.5)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace)\n",
       "      (5): Dropout(p=0.5)\n",
       "    )\n",
       "  )\n",
       "  (rpn_net): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
       "  (rpn_cls_score_net): Conv2d(512, 18, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (rpn_bbox_pred_net): Conv2d(512, 36, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (cls_score_net): Linear(in_features=4096, out_features=21, bias=True)\n",
       "  (bbox_pred_net): Linear(in_features=4096, out_features=84, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建网络结构，模型加入ROI数据层\n",
    "sw.data_layer = RoIDataLayer(sw.roidb, sw.imdb.num_classes)\n",
    "sw.data_layer_val = RoIDataLayer(sw.valroidb, sw.imdb.num_classes, random=True)\n",
    "\n",
    "# 构建网络结构，在VGG16基础上加入ROI和Classifier部分\n",
    "lr, train_op = sw.construct_graph()\n",
    "\n",
    "# 加载之前的snapshot\n",
    "lsf, nfiles, sfiles = sw.find_previous()\n",
    "\n",
    "# snapshot 为训练提供了断点训练，如果有snapshot将加载进来，继续训练\n",
    "if lsf == 0:\n",
    "    lr, last_snapshot_iter, stepsizes, np_paths, ss_paths = sw.initialize(\n",
    "    )\n",
    "else:\n",
    "    lr, last_snapshot_iter, stepsizes, np_paths, ss_paths = sw.restore(\n",
    "        str(sfiles[-1]), str(nfiles[-1]))\n",
    "iter = last_snapshot_iter + 1\n",
    "last_summary_time = time.time()\n",
    "# 在之前的训练基础上继续进行训练\n",
    "stepsizes.append(max_iters)\n",
    "stepsizes.reverse()\n",
    "next_stepsize = stepsizes.pop()\n",
    "# 对net切换成训练模式\n",
    "print(\"网络结构\")\n",
    "sw.net.train()\n",
    "sw.net.to(sw.net._device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1010 / 1200, total loss: 1.111544\n",
      " >>> rpn_loss_cls: 0.132086\n",
      " >>> rpn_loss_box: 0.047608\n",
      " >>> loss_cls: 0.371774\n",
      " >>> loss_box: 0.560076\n",
      " >>> lr: 0.001000\n",
      "speed: 0.129s / iter\n",
      "iter: 1020 / 1200, total loss: 1.315273\n",
      " >>> rpn_loss_cls: 0.108653\n",
      " >>> rpn_loss_box: 0.052084\n",
      " >>> loss_cls: 0.648501\n",
      " >>> loss_box: 0.506036\n",
      " >>> lr: 0.001000\n",
      "speed: 0.127s / iter\n",
      "iter: 1030 / 1200, total loss: 0.584790\n",
      " >>> rpn_loss_cls: 0.130646\n",
      " >>> rpn_loss_box: 0.007096\n",
      " >>> loss_cls: 0.303233\n",
      " >>> loss_box: 0.143815\n",
      " >>> lr: 0.001000\n",
      "speed: 0.128s / iter\n",
      "iter: 1040 / 1200, total loss: 1.648899\n",
      " >>> rpn_loss_cls: 0.367199\n",
      " >>> rpn_loss_box: 0.325622\n",
      " >>> loss_cls: 0.578676\n",
      " >>> loss_box: 0.377402\n",
      " >>> lr: 0.001000\n",
      "speed: 0.128s / iter\n",
      "iter: 1050 / 1200, total loss: 1.302446\n",
      " >>> rpn_loss_cls: 0.066994\n",
      " >>> rpn_loss_box: 0.023159\n",
      " >>> loss_cls: 0.408805\n",
      " >>> loss_box: 0.803488\n",
      " >>> lr: 0.001000\n",
      "speed: 0.128s / iter\n",
      "iter: 1060 / 1200, total loss: 1.470572\n",
      " >>> rpn_loss_cls: 0.179594\n",
      " >>> rpn_loss_box: 0.024960\n",
      " >>> loss_cls: 0.633082\n",
      " >>> loss_box: 0.632935\n",
      " >>> lr: 0.001000\n",
      "speed: 0.128s / iter\n",
      "iter: 1070 / 1200, total loss: 0.397713\n",
      " >>> rpn_loss_cls: 0.079580\n",
      " >>> rpn_loss_box: 0.002726\n",
      " >>> loss_cls: 0.195426\n",
      " >>> loss_box: 0.119982\n",
      " >>> lr: 0.001000\n",
      "speed: 0.127s / iter\n",
      "iter: 1080 / 1200, total loss: 1.072784\n",
      " >>> rpn_loss_cls: 0.060912\n",
      " >>> rpn_loss_box: 0.067176\n",
      " >>> loss_cls: 0.590563\n",
      " >>> loss_box: 0.354133\n",
      " >>> lr: 0.001000\n",
      "speed: 0.127s / iter\n",
      "iter: 1090 / 1200, total loss: 1.235246\n",
      " >>> rpn_loss_cls: 0.209192\n",
      " >>> rpn_loss_box: 0.031636\n",
      " >>> loss_cls: 0.663273\n",
      " >>> loss_box: 0.331144\n",
      " >>> lr: 0.001000\n",
      "speed: 0.127s / iter\n",
      "iter: 1100 / 1200, total loss: 0.857316\n",
      " >>> rpn_loss_cls: 0.487935\n",
      " >>> rpn_loss_box: 0.230730\n",
      " >>> loss_cls: 0.125887\n",
      " >>> loss_box: 0.012765\n",
      " >>> lr: 0.001000\n",
      "speed: 0.127s / iter\n",
      "iter: 1110 / 1200, total loss: 0.756913\n",
      " >>> rpn_loss_cls: 0.185020\n",
      " >>> rpn_loss_box: 0.030284\n",
      " >>> loss_cls: 0.362152\n",
      " >>> loss_box: 0.179458\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1120 / 1200, total loss: 1.025235\n",
      " >>> rpn_loss_cls: 0.047321\n",
      " >>> rpn_loss_box: 0.111944\n",
      " >>> loss_cls: 0.383440\n",
      " >>> loss_box: 0.482530\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1130 / 1200, total loss: 0.930075\n",
      " >>> rpn_loss_cls: 0.233261\n",
      " >>> rpn_loss_box: 0.024933\n",
      " >>> loss_cls: 0.431336\n",
      " >>> loss_box: 0.240546\n",
      " >>> lr: 0.001000\n",
      "speed: 0.127s / iter\n",
      "iter: 1140 / 1200, total loss: 1.040723\n",
      " >>> rpn_loss_cls: 0.149801\n",
      " >>> rpn_loss_box: 0.028038\n",
      " >>> loss_cls: 0.554749\n",
      " >>> loss_box: 0.308135\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1150 / 1200, total loss: 2.306713\n",
      " >>> rpn_loss_cls: 0.279719\n",
      " >>> rpn_loss_box: 0.151981\n",
      " >>> loss_cls: 1.255473\n",
      " >>> loss_box: 0.619540\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1160 / 1200, total loss: 1.346372\n",
      " >>> rpn_loss_cls: 0.135573\n",
      " >>> rpn_loss_box: 0.065106\n",
      " >>> loss_cls: 0.552092\n",
      " >>> loss_box: 0.593601\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1170 / 1200, total loss: 1.245602\n",
      " >>> rpn_loss_cls: 0.068168\n",
      " >>> rpn_loss_box: 0.076471\n",
      " >>> loss_cls: 0.521073\n",
      " >>> loss_box: 0.579890\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1180 / 1200, total loss: 1.521659\n",
      " >>> rpn_loss_cls: 0.259899\n",
      " >>> rpn_loss_box: 0.024292\n",
      " >>> loss_cls: 0.682296\n",
      " >>> loss_box: 0.555171\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1190 / 1200, total loss: 1.734838\n",
      " >>> rpn_loss_cls: 0.120302\n",
      " >>> rpn_loss_box: 0.113281\n",
      " >>> loss_cls: 0.892284\n",
      " >>> loss_box: 0.608971\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "iter: 1200 / 1200, total loss: 1.310779\n",
      " >>> rpn_loss_cls: 0.190671\n",
      " >>> rpn_loss_box: 0.028231\n",
      " >>> loss_cls: 0.505375\n",
      " >>> loss_box: 0.586502\n",
      " >>> lr: 0.001000\n",
      "speed: 0.126s / iter\n",
      "Wrote snapshot to: /home/ma-user/work/output/default/voc_2007_trainval/default/res101_faster_rcnn_iter_1200.pth\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "\n",
    "while iter < max_iters + 1:\n",
    "    cfg.SNAPSHOT_PREFIX = \"VGG_faster_rcnn\"\n",
    "    if iter == next_stepsize + 1:\n",
    "        # 加入snapshot节点\n",
    "        sw.snapshot(iter)\n",
    "        lr *= cfg.TRAIN.GAMMA\n",
    "        scale_lr(sw.optimizer, cfg.TRAIN.GAMMA)\n",
    "        next_stepsize = stepsizes.pop()\n",
    "\n",
    "    utils.timer.timer.tic()\n",
    "    # 数据通过ROI数据层，进行前向计算\n",
    "    blobs = sw.data_layer.forward()\n",
    "\n",
    "    now = time.time()\n",
    "    if iter == 1 or now - last_summary_time > cfg.TRAIN.SUMMARY_INTERVAL:\n",
    "        # 计算loss函数\n",
    "        # 根据loss函数对模型进行训练\n",
    "        rpn_loss_cls, rpn_loss_box, loss_cls, loss_box, total_loss, summary = \\\n",
    "          sw.net.train_step_with_summary(blobs, sw.optimizer)\n",
    "        for _sum in summary:\n",
    "            sw.writer.add_summary(_sum, float(iter))\n",
    "        # 进行数据层验证计算\n",
    "        blobs_val = sw.data_layer_val.forward()\n",
    "        summary_val = sw.net.get_summary(blobs_val)\n",
    "        for _sum in summary_val:\n",
    "            sw.valwriter.add_summary(_sum, float(iter))\n",
    "        last_summary_time = now\n",
    "    else:\n",
    "        rpn_loss_cls, rpn_loss_box, loss_cls, loss_box, total_loss = \\\n",
    "          sw.net.train_step(blobs, sw.optimizer)\n",
    "    utils.timer.timer.toc()\n",
    "\n",
    "    if iter % (cfg.TRAIN.DISPLAY) == 0:\n",
    "        print('iter: %d / %d, total loss: %.6f\\n >>> rpn_loss_cls: %.6f\\n '\n",
    "              '>>> rpn_loss_box: %.6f\\n >>> loss_cls: %.6f\\n >>> loss_box: %.6f\\n >>> lr: %f' % \\\n",
    "              (iter, max_iters, total_loss, rpn_loss_cls, rpn_loss_box, loss_cls, loss_box, lr))\n",
    "        print('speed: {:.3f}s / iter'.format(\n",
    "            utils.timer.timer.average_time()))\n",
    "\n",
    "    # 进行snapshot存储\n",
    "    if iter % cfg.TRAIN.SNAPSHOT_ITERS == 0:\n",
    "        last_snapshot_iter = iter\n",
    "        ss_path, np_path = sw.snapshot(iter)\n",
    "        np_paths.append(np_path)\n",
    "        ss_paths.append(ss_path)\n",
    "\n",
    "        # 删掉多余的snapshot\n",
    "        if len(np_paths) > cfg.TRAIN.SNAPSHOT_KEPT:\n",
    "            sw.remove_snapshot(np_paths, ss_paths)\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "if last_snapshot_iter != iter - 1:\n",
    "    sw.snapshot(iter - 1)\n",
    "\n",
    "sw.writer.close()\n",
    "sw.valwriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
